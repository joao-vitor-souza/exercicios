{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e5bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operações matemáticas.\n",
    "import numpy as np\n",
    "\n",
    "# Plotagem gráfica.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pré-processamento.\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Rede Neural e componentes.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f9699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semente de reprodução.\n",
    "tf.random.set_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a98370",
   "metadata": {},
   "source": [
    "#### Carregando o caminho das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3ac75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\fruits-360\\\\Training\\\\Apple Braeburn\\\\0_100.jpg',\n",
       " '..\\\\fruits-360\\\\Training\\\\Apple Braeburn\\\\100_100.jpg',\n",
       " '..\\\\fruits-360\\\\Training\\\\Apple Braeburn\\\\101_100.jpg',\n",
       " '..\\\\fruits-360\\\\Training\\\\Apple Braeburn\\\\102_100.jpg',\n",
       " '..\\\\fruits-360\\\\Training\\\\Apple Braeburn\\\\103_100.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando caminhos.\n",
    "train_path = Path(\"../fruits-360/Training\")\n",
    "test_path = Path(\"../fruits-360/Test\")\n",
    "\n",
    "# Recuperando o nome de todos as pastas e seus arquivos.\n",
    "train_images = list(train_path.glob(\"*/*\"))\n",
    "train_images = list(map(lambda x: str(x), train_images))\n",
    "\n",
    "train_images[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c86a8",
   "metadata": {},
   "source": [
    "### Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8c4898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple Braeburn',\n",
       " 'Apple Braeburn',\n",
       " 'Apple Braeburn',\n",
       " 'Apple Braeburn',\n",
       " 'Apple Braeburn']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraindo labels.\n",
    "extract_file = lambda x: x.split(\"\\\\\")[-2]\n",
    "train_labels = list(map(lambda x: extract_file(x), train_images))\n",
    "\n",
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850e3c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codificação das labels.\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "\n",
    "# One-hot encoding.\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "train_labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5843e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando em conjuntos de treino e validação\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fc40dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função de redimensionamento.\n",
    "img_size = 224\n",
    "resize = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Resizing(img_size, img_size)])\n",
    "\n",
    "# Dataset Augmentation\n",
    "data_augmentation = tf.keras.Sequential([RandomFlip(\"horizontal\"),  # Inversão;\n",
    "                                         RandomRotation(0.2),       # Rotação;\n",
    "                                         RandomZoom((-0.3, -0.2))]) # Zoom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f25b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho dos lotes de imagens a serem treinados.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81f1a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar imagem.\n",
    "def load_transform(image):\n",
    "    \n",
    "    # Lê a imagem.\n",
    "    image = tf.io.read_file(image)\n",
    "    \n",
    "    # Decodifica de JPEG para um tensor de com 3 canais de cores.\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0869c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preparar os dados.\n",
    "def prepare_dataset(paths, labels, train=True):\n",
    "    \n",
    "    # Conversão para tensores.\n",
    "    image_paths = tf.convert_to_tensor(paths)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    \n",
    "    # Criando datasets a partir dos tensores.\n",
    "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    \n",
    "    # Pareando a imagem a seu respectivo rótulo.\n",
    "    dataset = tf.data.Dataset.zip((image_dataset, label_dataset))\n",
    "    \n",
    "    # Carregando e redimensionando imagem.\n",
    "    dataset = dataset.map(lambda image, label: (load_transform(image), label))\n",
    "    dataset = dataset.map(lambda image, label: (resize(image), label), \n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # Embaralhando os dados e formando os lotes.\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    # Se os dados forem de treino, então fazemos o Data Augmentation.\n",
    "    if train:\n",
    "        dataset = dataset.map(lambda image, label: (data_augmentation(image), label), \n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea161e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando os conjuntos.\n",
    "train_dataset = prepare_dataset(X_train, y_train)\n",
    "valid_dataset = prepare_dataset(X_valid, y_valid, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e603fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 224, 224, 3]), TensorShape([32, 131]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(train_dataset))\n",
    "\n",
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699fb8a",
   "metadata": {},
   "source": [
    "##### Cada lote tem 32 imagens, cada imagem tem 224 x 224 pixels e 3 canais de cores, além de 131 rótulos disponíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b5403",
   "metadata": {},
   "source": [
    "### Modelo Convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e824116",
   "metadata": {},
   "source": [
    "#### Construindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ff0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Arquitetura da rede neural, sem a última camada.\n",
    "        EfficientNetB3(input_shape=(224, 224, 3), include_top=False),\n",
    "        \n",
    "        # Redução para 2 dimensões.\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Adicionando a última camada, com as 131 classes disponíveis.\n",
    "        tf.keras.layers.Dense(131, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5732b639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb3 (Functional)  (None, 7, 7, 1536)       10783535  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1536)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 131)               201347    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,984,882\n",
      "Trainable params: 10,897,579\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534d5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores dos hiperparâmetros.\n",
    "lr, beta1, beta2, ep = 1e-3, .9, .999, 1e-7\n",
    "\n",
    "# Compilação do modelo.\n",
    "model.compile(\n",
    "    # Algoritmo de backpropagation.\n",
    "    optimizer = Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2, epsilon=ep),\n",
    "    \n",
    "    # Função de custo.\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    \n",
    "    # Métricas de avaliação.\n",
    "    metrics = [\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a03c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando callbacks.\n",
    "\n",
    "# Checkpoint para salvar os pesos do melhor modelo.\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"../models/best_model.h5\",\n",
    "                                                verbose=1,\n",
    "                                                save_best=True,\n",
    "                                                save_weights_only=True)\n",
    "\n",
    "# EarlyStopping com espera de 4 iterações.\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando modelo...\n",
    "model.fit(train_dataset,\n",
    "          steps_per_epoch = len(X_train)//batch_size,\n",
    "          epochs = 6,\n",
    "          validation_data = valid_dataset,\n",
    "          validation_steps = len(y_train)//batch_size,\n",
    "          callbacks = [checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a716cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os pesos do modelo treinado.\n",
    "model.load_weights(\"../models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ce1b8",
   "metadata": {},
   "source": [
    "#### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8399b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o mesmo pré-processamento aos dados de teste.\n",
    "test_images = list(test_path.glob(\"*/*\"))\n",
    "test_images = list(map(lambda x: str(x), test_images))\n",
    "test_labels = list(map(lambda x: extract_file(x), test_images))\n",
    "test_labels = encoder.fit_transform(test_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "test_image_paths = tf.convert_to_tensor(test_images)\n",
    "test_image_labels = tf.convert_to_tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ced45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para decodificar e redimensionar imagens.\n",
    "def decode_images(image, label):\n",
    "    \n",
    "    image = tf.io.read_file(image)\n",
    "    image = tf.io.decode_jpeg(image, channels = 3)\n",
    "    image = tf.image.resize(image, [224, 224], method = \"bilinear\")\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c210a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataset de teste com as mesmas configurações que o dataset de treino.\n",
    "test_dataset = (tf.data.Dataset\n",
    "                .from_tensor_slices((test_images, test_labels))\n",
    "                .map(decode_images)\n",
    "                .batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b738a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, prec, rec = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db461be",
   "metadata": {},
   "source": [
    "#### Acurácia: 0.7616\n",
    "#### Precisão: 0.7857\n",
    "#### Revocação: 0.7499"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
